---
- name: Build master image based on ubuntu 18.04 updated 04/12/2020
  hosts: localhost
  connection: local
  gather_facts: False
  vars:
###################################################################

    course_name: trainubnt18img
    instance_type: g4dn.2xlarge

###################################################################
    project_name: OSSF-Training
    # TrainingBioExcel TrainingSingleCell OSSF-Training TrainingJointWellcome
    security_group: Training-DCV
    subnetid: subnet-818b85f9
    trainingpassword: "{{ trpass }}"
    keypair: "{{ trkeypair }}"
    region: eu-west-2
    count: 1
  vars_files:
    - aws_keys.yml

  tasks:
#  - name: Create a security group
#      ec2_group:
#        name: "{{ security_group }}"
#        description: The Nice DCV security group
#        vpc_id: vpc-a458bacd
#        region: "{{ region }}"
#        aws_secret_key: "{{ aws_secret_key }}"
#        rules:
#          - proto: tcp
#            from_port: 22
#            to_port: 22
#            cidr_ip: 0.0.0.0/0
#          - proto: tcp
#            from_port: 8443
#            to_port: 8443
#            cidr_ip: 0.0.0.0/0
#          - proto: tcp
#            from_port: 2049
#            to_port: 2049
#            cidr_ip: sg-0903018d68dbdbbd3
#          - proto: tcp
#            from_port: 443
#            to_port: 443
#            cidr_ip: 0.0.0.0/0
#        rules_egress:
#          - proto: all
#            cidr_ip: 0.0.0.0/0

    - name: Aquiring the Ubuntu 18.04 AMIs image
      amazon.aws.ec2_ami_info:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        region: "{{ region }}"
        owners: 099720109477 # Canonical
        filters:
          name: "ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-*"
      register: ec2_ami

    - set_fact:
        ec2_ami_latest: "{{ ec2_ami.images | selectattr('name', 'defined') | sort(attribute='creation_date') | last }}"

    - name: Launch the new EC2 Instance
      ec2:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        group: "{{ security_group }}"
        instance_type: "{{ instance_type }}"
        image: "{{ ec2_ami_latest.image_id }}"
        wait: true
        vpc_subnet_id: "{{ subnetid }}"
        region: "{{ region }}"
        keypair: "{{ keypair }}"
        count: "{{ count }}"
        monitoring: no
        tenancy: default
        ### default dedicated host
        assign_public_ip: yes
        instance_profile_name: "{{ vmprofile }}"
        volumes:
          - device_name: /dev/sda1
            volume_type: io1
            iops: 3000
            volume_size: 300
            delete_on_termination: true
        instance_tags:
          Course: "{{ course_name }}"
          team: TrainingTeam
          Owner: "{{ scriptuser }}"
          project: "{{ project_name }}"
      register: ec2

    - name: Add the newly created host so that we can further contact it
      add_host:
        name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
        instance_name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
        ansible_host: "{{ item.public_ip }}"
        groups: awsfloat
        remote_user: "{{ rmtuser }}"
        ansible_user: "{{ rmtuser }}"
        ansible_ssh_user: "{{ rmtuser }}"
        become: True
        ansible_ssh_private_key_file: "{{ ssh_key_file }}"
        efs_file_system_dns: "{{ efsvolume }}"
        efs_mount_dir: "{{ efsmount }}"
        trainingpassword: "{{ trpass }}"
      with_items: "{{ ec2.instances }}"

    - name: Add Name tag to Instance(s)
      ec2_tag:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        resource: "{{ item.id }}"
        region: "{{ region }}"
        state: "present"
        tags:
          Name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
          Project: "{{ project_name }}"
          Team: TrainingTeam
          owner: "{{ scriptuser }}"
      with_items: "{{ ec2.instances }}"

    - name: Wait for SSH to come up
      wait_for:
        host: "{{ item.public_ip }}"
        port: 22
        state: started
      with_items: "{{ ec2.instances }}"

    - name: Remove old VMs pool file from inventory
      file:
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        state: absent
      ignore_errors: yes

    - name: Fill in VMs pool inventory file
      blockinfile:
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        create: yes
        block: |
          [{{ course_name }}:vars]
          ansible_ssh_private_key_file={{ ssh_key_file }}
          remote_user={{ rmtuser }}
          efs_file_system_dns={{ efsvolume }}
          efs_mount_dir={{ efsmount }}
          trainingpassword={{ trpass }}
          become=True

          [{{ course_name }}]

    - name: Fill in the local backup pool inventory file
      lineinfile:
        line: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}   ansible_host={{ item.public_ip }}"
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        insertafter: EOF
      with_items: "{{ ec2.instances }}"

    - name: Create the DCV folder for the course
      file:
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}"
        state: directory

    - name: Create the DCV files
      blockinfile:
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}/{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}.dcv"
        create: yes
        block: |
          [version]
          format=1.0

          [options]
          fullscreen=true

          [connect]
          host=1.2.3.4
          port=8443
          user=training
          password=training
          proxytype=system
      with_items: "{{ ec2.instances }}"

    - name: Create DCV Desktop files for users to users
      lineinfile:
        line: "host={{ item.public_ip }}"
        regexp: '^host='
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}/{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}.dcv"
        state: present
      with_items: "{{ ec2.instances }}"

    #- name: Configure DCV Desktop files for Thin Clients
    #  lineinfile:
    #    line: "host={{ item.1.public_ip }}"
    #    regexp: '^host='
    #    path: "/Users/alibi/aws-ansible/dcv-files/{{ item.0 }}.dcv"
    #    state: present
    #  with_together:
    #     - "{{ groups.ThinClientTR1 }}"
    #     - "{{ ec2.instances }}"
    #  ignore_errors: yes

##########################################################################
##########################################################################
- hosts: awsfloat
  ###awstrainingroom
  name: Configure AWS instances OS
  become: True
  remote_user: ubuntu
  gather_facts: False
  vars:
    trainingpassword: training
    ansible_ssh_private_key_file: /Users/alibi/aws-ansible/Training.pem
  pre_tasks:
    - name: Change instance hostname
      lineinfile:
        path: /etc/hostname
        regexp: '^ip'
        line: "{{inventory_hostname}}"
        owner: root
        group: root
        mode: '0644'

    - name: Change hosts hostname entry
      lineinfile:
        path: /etc/hosts
        insertafter: '^127\.0\.0\.1'
        line: "127.0.1.1 {{inventory_hostname}}"
        owner: root
        group: root
        mode: '0644'

    - name: Update the software cache
      apt: update_cache=yes

    - name: Install Aptitude
      apt:
        name: aptitude

    - name: Add extra repos
      shell: add-apt-repository -y ppa:atareao/atareao && apt install -y linux-headers-$(uname -r)

    - name: Install Ubuntu Repo based tools
      apt:
        name: "{{ packages }}"
        update_cache: yes
      vars:
        packages:
        - autoconf
        - libtool
        - openjdk-8-jre
        - default-jre
        - openjdk-8-jre-headless
        - libcanberra-gtk3-module
        - libcanberra-gtk-module
        - libxml2-dev
        - libxml2
        - liblzma-dev
        - curl
        - libcurl4-openssl-dev
        - build-essential
        - make
        - gcc
        - automake
        - libssl-dev
        - zlib1g-dev
        - libbz2-dev
        - python3
        - python
        - python3-pip
        - python-pip
        - gnome-session
        - ubuntu-desktop
        - lightdm
        - mesa-utils
        - power-commands
        - chromium-browser
        - ubuntu-restricted-extras
        - unrar
        - rar
        - icedax
        - lame
        - sharutils
        - unace
        - zip
        - unzip
        - p7zip-full
        - p7zip-rar
        - flashplugin-installer
        - bleachbit
        - openssh-server
        - htop
        - nload
        - git
        - python-dbus
        - python-gobject
        - libmpeg3-dev
        - cmake
        - libjpeg8
        - libglib2.0-dev
        - libglib2.0-0
        - libexpat1
        - libxss1
        - libudev1
        - libudev-dev
        - libflac++-dev
        - libflac-dev
        - libswscale-dev
        - expect
        - nfs-common
        - libglvnd-dev
        - libglvnd-core-dev
        - libglvnd0
        - pkg-config
        - x11-xserver-utils
        - gcc
        - make
        - linux-aws
        - awscli
        - ubuntu-desktop
        - xterm
        - xorg
        - grace
        - libncurses5-dev
        - libncursesw5-dev
        - libxbae4m
        - subversion
        - python3-dev
        - sudo

#    - name: Remove gdm3 and what follows
#      apt:
#        name: "{{ packages }}"
#        state: absent
#      vars:
#        packages:
#        - gdm3
#        - gnome-initial-setup
#      ignore_errors: yes

    - name: Install languepacks
      shell: |
        apt -y install `check-language-support -l fr`
        apt -y install `check-language-support -l en`
        apt -y install `check-language-support -l es`
        apt -y install `check-language-support -l de`
        apt -y install `check-language-support -l it`

    - name: Set lightdm as default display manager
      script: /Users/alibi/aws-ansible/dpkgreconfig

    - name: Upgrade all software
      apt: upgrade=yes

    - name: Remove useless packages from the cache
      apt:
        autoclean: yes

    - name: Remove dependencies that are no longer required
      apt:
        autoremove: yes

    - name: Reboot the VMs to enable LINUX-AWS package
      reboot:
        msg: System reboot inititated by Ansible
        reboot_timeout: 120

    - name: Configrue nvidia driver black list on modprob
      blockinfile:
        path: /etc/modprobe.d/blacklist.conf
        block: |
          blacklist vga16fb
          blacklist nouveau
          blacklist rivafb
          blacklist nvidiafb
          blacklist rivatv

    - name: Add nouveau blacklist to grub
      lineinfile: dest=/etc/default/grub regexp='^GRUB_CMDLINE_LINUX=""' line='GRUB_CMDLINE_LINUX="rdblacklist=nouveau"'

    - name: Update Grub settings to apply new blacklist changes
      shell: sudo update-grub

    - name: Download the Nvidia G4 Driver from AWS S3
      shell: aws s3 cp --recursive s3://ec2-linux-nvidia-drivers/g4/latest/ /usr/local/

    - name: Set Nvidia driver execute permissions
      shell: chmod +x /usr/local/NVIDIA-Linux-x86_64*.run

    - name: Stop X server to install nvidia driver
      shell: |
        systemctl stop lightdm
        systemctl stop gdm3

    - name: Install NVIDIA GRID driver
      shell: sudo /bin/sh /usr/local/NVIDIA-Linux-x86_64*.run -q -a -n -X -s
      async: 60
      poll: 5

    - name: Start X server to install nvidia driver
      shell: |
        systemctl start lightdm

    - name: Remove NVIDIA driver installer file
      shell: rm /usr/local/NVIDIA-Linux-x86_64*.run
      ignore_errors: yes

    - name: Reboot the VMs to enable Nvidia GRID Driver
      reboot:
        msg: System reboot inititated by Ansible
        reboot_timeout: 120

    #- name: Add nvidia grid conf
    #  lineinfile: dest=/etc/nvidia/gridd.conf regexp='^EnableUI=FALSE' line='EnableUI=TRUE'

    - name: Configure Apport to stop messing around
      lineinfile:
        dest: /etc/default/apport
        regexp: '^enabled=1'
        line: enabled=0

    - name: Stop new LTS release promotion box
      shell: sudo sed -i 's/Prompt=.*/Prompt=never/' /etc/update-manager/release-upgrades


    - name: Stop gdm initial setup
      lineinfile:
        dest: /etc/gdm3/custom.conf
        regexp: '^# Enabling timed login'
        line: 'InitialSetupEnable=false'

    - name: Stop gdm initial setup 2.0
      lineinfile:
        dest: /etc/xdg/autostart/gnome-initial-setup-first-login.desktop
        regexp: '^Exec=/usr/lib/gnome-initial-setup/gnome-initial-setup --existing-user'
        line: '##Exec=/usr/lib/gnome-initial-setup/gnome-initial-setup --existing-user'

    - name: Add the user training
      user:
        name: training
        comment: Training
        password: "{{ trainingpassword | password_hash('sha512') }}"
        shell: /bin/bash
        groups: sudo,audio,video
        append: yes
        home: /home/training
      ignore_errors: true

    - name: Create training user Desktop folder
      file:
        path: /home/training/Desktop/
        state: directory
        mode: 0755
        owner: training
        group: training

    - name: Create PenleopeCloud folder
      file:
        path: "{{ efs_mount_dir }}"
        state: directory
        mode: 0777
        owner: training
        group: training

    - name: Ensure EFS volume is mounted.
      mount:
        path: "{{ efs_mount_dir }}"
        src: "{{ efs_file_system_dns }}:/"
        fstype: nfs
        opts: defaults
        #vers=4
        state: mounted

    - name: Change training user login method
      shell: gpasswd -a training nopasswdlogin
      ignore_errors: true

    - name: Update lightdm config
      blockinfile:
        path: /etc/lightdm/lightdm.conf
        create: yes
        block: |
          [SeatDefaults]
          autologin-user=training
          autologin-guest=false
          [Seat:seat*]
          greeter-setup-script=xhost +LOCAL:

    - name: Update lightdm config
      blockinfile:
        path: /var/lib/AccountsService/users/ubuntu
        create: yes
        block: |
          [User]
          SystemAccount=true

    - name: Set graphical target
      shell: systemctl get-default && systemctl set-default graphical.target && systemctl isolate graphical.target

    - name: Run an Nvidia xconfig
      shell: nvidia-xconfig

    - name: Add an apt key for Nice DCV repo
      shell: wget https://d1uj6qtbmh3dt5.cloudfront.net/NICE-GPG-KEY -P /usr/local/ && gpg --import /usr/local/NICE-GPG-KEY

    - name: Get and extract Nice DCV server archive
      unarchive:
        src: "https://d1uj6qtbmh3dt5.cloudfront.net/2020.2/Servers/nice-dcv-2020.2-9508-ubuntu1804-x86_64.tgz"
        dest: /usr/local/
        remote_src: yes
        mode: '0777'

    - name: Install the Nice DCV server deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-server_2020.2.9508-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV xdcv deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-xdcv_2020.2.359-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV GPU sharing dcv-gl deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-gl_2020.2.881-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV dcv-gl test deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-gltest_2020.2.259-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV simple external auth deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-simple-external-authenticator_2020.2.125-1_amd64.ubuntu1804.deb

    - name: Delete DCV server deb packages installer
      file:
        path: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64
        state: absent

    - name: Install DKMS USB driver
      apt:
        name: dkms

    - name: Install the DCV USB drivers
      shell: dcvusbdriverinstaller --quiet

    - name: Fix console sessions
      shell: systemctl isolate multi-user.target && dcvgladmin disable && dcvgladmin enable && systemctl isolate graphical.target

    - name: Reconfigure dcvserver config file session creation
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#create-session = true' line='create-session = true'

    - name: Reconfigure dcvserver config file virtual-session
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#enable-gl-in-virtual-sessions = "default-on"' line='enable-gl-in-virtual-sessions = "default-on"'

    - name: Reconfigure dcvserver config file owner
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#owner = ""' line='owner="training"'

    - name: Reconfigure dcvserver config file owner
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#authentication="none"' line='authentication="system"'

    - name: Reconfigure dcvserver config file timeout
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#idle-timeout=120' line='idle-timeout=600'

    - name: Reconfigure dcvserver config file
      blockinfile:
        path: /etc/dcv/dcv.conf
        block: |
          cuda-devices=['0']
          [display/linux]
          gl-displays=[':0.0',':0.1']
          [clipboard]
          primary-selection-paste=true

    - name: Service dcvserver enable and start
      shell: systemctl enable dcvserver && systemctl restart dcvserver

    - name: Reboot the course instances to apply update and enable drivers
      reboot:
        msg: System reboot inititated by Ansible to start user session
        reboot_timeout: 120

################################################################################################
################################################################################################

  tasks:
  - name: Create PeneloepCloud Tools folder
    file:
      path: /media/penelopecloud/tools/
      state: directory
      mode: 0777
      owner: training
      group: training
    poll: 1

##########################################################################
##########################################################################
# Desktop configuration ################################################
  - name: Copy Chromium Desktop file
    copy:
      src: /usr/share/applications/chromium-browser.desktop
      dest: /home/training/Desktop/chromium-browser.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Firefox Desktop file
    copy:
      src: /usr/share/applications/firefox.desktop
      dest: /home/training/Desktop/firefox.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Terminal Desktop file
    copy:
      src: /usr/share/applications/gnome-terminal.desktop
      dest: /home/training/Desktop/gnome-terminal.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Word Desktop file
    copy:
      src: /usr/share/applications/libreoffice-writer.desktop
      dest: /home/training/Desktop/libreoffice-writer.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Excel Desktop file
    copy:
      src: /usr/share/applications/libreoffice-calc.desktop
      dest: /home/training/Desktop/libreoffice-calc.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Create user autostater folder
    file:
      path: /home/training/.config/autostart
      state: directory

  - name: Create Desktop truster desktop file
    file:
      path: /home/training/.config/autostart/desktop-truster.desktop
      state: touch
      owner: training
      group: training
      mode: '0777'


  - name: Create Desktop truster Bash script file
    file:
      path: /home/training/.config/autostart/desktop-truster.sh
      state: touch
      owner: training
      group: training
      mode: '0777'


  - name: Fill-in Desktop truster desktop file
    blockinfile:
      path: /home/training/.config/autostart/desktop-truster.desktop
      block: |
        [Desktop Entry]
        Type=Application
        Comment=Autostarter to trust all desktop files
        Terminal=false
        Name=Desktop Truster
        Exec=/home/training/.config/autostart/desktop-truster.sh

  - name: Fill-in Desktop truster Bash script file
    blockinfile:
      path: /home/training/.config/autostart/desktop-truster.sh
      block: |
        #!/bin/bash
        # Wait for nautilus-desktop
        while ! pgrep -f 'nautilus-desktop' > /dev/null; do
          sleep 1
        done
        # enable user home default desktop icons
        gsettings set org.gnome.nautilus.desktop home-icon-visible  'true'
        gsettings set org.gnome.nautilus.desktop volumes-visible 'true'
        gsettings set org.gnome.nautilus.desktop trash-icon-visible 'true'
        gsettings set org.gnome.desktop.lockdown disable-lock-screen 'true'
        gsettings set org.gnome.desktop.screensaver lock-enabled 'false'
        # Trust all desktop files
        for i in /home/training/Desktop/*.desktop; do
          [ -f "${i}" ] || break
          gio set "${i}" "metadata::trusted" yes
          # gio set "${i}" "metadata::trusted" true (ubuntu 19.04 onward)
        done
        # Restart nautilus, so that the changes take effect (otherwise we would have to press F5)
        killall nautilus-desktop && nautilus-desktop &
        # Remove X from this script, so that it won't be executed next time
        chmod -x ${0}

  - name: Reboot the course instances to apply fixes and tweaks
    reboot:
      msg: System reboot inititated by Ansible to start user session
      reboot_timeout: 120

##########################################################################
##########################################################################
