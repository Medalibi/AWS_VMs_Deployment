---
- name: Deploy Nice DCV powered Ubuntu 18.04 instances on AWS ioExcel Winter School December 2020 (Virtual) build playbook on 18-09-2020
  hosts: localhost
  connection: local
  gather_facts: False
  vars:
###################################################################

    course_name: bioexclwinshl20
    instance_type: g4dn.2xlarge

###################################################################
    project_name: OSSF-Training
    # TrainingBioExcel TrainingSingleCell OSSF-Training TrainingJointWellcome
    security_group: Training-DCV
    subnetid: subnet-818b85f9
    trainingpassword: "{{ trpass }}"
    keypair: "{{ trkeypair }}"
    region: eu-west-2
    count: 3
  vars_files:
    - aws_keys.yml

  tasks:
#  - name: Create a security group
#      ec2_group:
#        name: "{{ security_group }}"
#        description: The Nice DCV security group
#        vpc_id: vpc-a458bacd
#        region: "{{ region }}"
#        aws_secret_key: "{{ aws_secret_key }}"
#        rules:
#          - proto: tcp
#            from_port: 22
#            to_port: 22
#            cidr_ip: 0.0.0.0/0
#          - proto: tcp
#            from_port: 8443
#            to_port: 8443
#            cidr_ip: 0.0.0.0/0
#          - proto: tcp
#            from_port: 2049
#            to_port: 2049
#            cidr_ip: sg-0903018d68dbdbbd3
#          - proto: tcp
#            from_port: 443
#            to_port: 443
#            cidr_ip: 0.0.0.0/0
#        rules_egress:
#          - proto: all
#            cidr_ip: 0.0.0.0/0

    - name: Aquiring the Ubuntu 18.04 AMIs image
      amazon.aws.ec2_ami_info:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        region: "{{ region }}"
        owners: 099720109477 # Canonical
        filters:
          name: "ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-*"
      register: ec2_ami

    - set_fact:
        ec2_ami_latest: "{{ ec2_ami.images | selectattr('name', 'defined') | sort(attribute='creation_date') | last }}"

    - name: Launch the new EC2 Instance
      ec2:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        group: "{{ security_group }}"
        instance_type: "{{ instance_type }}"
        image: "{{ ec2_ami_latest.image_id }}"
        wait: true
        vpc_subnet_id: "{{ subnetid }}"
        region: "{{ region }}"
        keypair: "{{ keypair }}"
        count: "{{ count }}"
        monitoring: no
        tenancy: default
        ### default dedicated host
        assign_public_ip: yes
        instance_profile_name: "{{ vmprofile }}"
        volumes:
          - device_name: /dev/sda1
            volume_type: io1
            iops: 3000
            volume_size: 300
            delete_on_termination: true
        instance_tags:
          Course: "{{ course_name }}"
          team: TrainingTeam
          Owner: "{{ scriptuser }}"
          project: "{{ project_name }}"
      register: ec2

    - name: Add the newly created host so that we can further contact it
      add_host:
        name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
        instance_name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
        ansible_host: "{{ item.public_ip }}"
        groups: awsfloat
        remote_user: "{{ rmtuser }}"
        ansible_user: "{{ rmtuser }}"
        ansible_ssh_user: "{{ rmtuser }}"
        become: True
        ansible_ssh_private_key_file: "{{ ssh_key_file }}"
        efs_file_system_dns: "{{ efsvolume }}"
        efs_mount_dir: "{{ efsmount }}"
        trainingpassword: "{{ trpass }}"
      with_items: "{{ ec2.instances }}"

    - name: Add Name tag to Instance(s)
      ec2_tag:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        resource: "{{ item.id }}"
        region: "{{ region }}"
        state: "present"
        tags:
          Name: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}"
          Project: "{{ project_name }}"
          Team: TrainingTeam
          owner: "{{ scriptuser }}"
      with_items: "{{ ec2.instances }}"

    - name: Wait for SSH to come up
      wait_for:
        host: "{{ item.public_ip }}"
        port: 22
        state: started
      with_items: "{{ ec2.instances }}"

    - name: Remove old VMs pool file from inventory
      file:
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        state: absent
      ignore_errors: yes

    - name: Fill in VMs pool inventory file
      blockinfile:
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        create: yes
        block: |
          [{{ course_name }}:vars]
          ansible_ssh_private_key_file={{ ssh_key_file }}
          remote_user={{ rmtuser }}
          efs_file_system_dns={{ efsvolume }}
          efs_mount_dir={{ efsmount }}
          trainingpassword={{ trpass }}
          become=True

          [{{ course_name }}]

    - name: Fill in the local backup pool inventory file
      lineinfile:
        line: "{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}   ansible_host={{ item.public_ip }}"
        path: "/Users/alibi/aws-ansible/hosts.d/{{ course_name }}"
        insertafter: EOF
      with_items: "{{ ec2.instances }}"

    - name: Create the DCV folder for the course
      file:
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}"
        state: directory

    - name: Create the DCV files
      blockinfile:
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}/{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}.dcv"
        create: yes
        block: |
          [version]
          format=1.0

          [options]
          fullscreen=true

          [connect]
          host=1.2.3.4
          port=8443
          user=training
          password=training
          proxytype=system
      with_items: "{{ ec2.instances }}"

    - name: Create DCV Desktop files for users to users
      lineinfile:
        line: "host={{ item.public_ip }}"
        regexp: '^host='
        path: "/Users/alibi/aws-ansible/dcv-files/{{ course_name }}/{{ course_name }}-{{ (item.ami_launch_index | int) + 1 }}.dcv"
        state: present
      with_items: "{{ ec2.instances }}"

    #- name: Configure DCV Desktop files for Thin Clients
    #  lineinfile:
    #    line: "host={{ item.1.public_ip }}"
    #    regexp: '^host='
    #    path: "/Users/alibi/aws-ansible/dcv-files/{{ item.0 }}.dcv"
    #    state: present
    #  with_together:
    #     - "{{ groups.ThinClientTR1 }}"
    #     - "{{ ec2.instances }}"
    #  ignore_errors: yes

##########################################################################
##########################################################################
- hosts: awsfloat
  ###awstrainingroom
  name: Configure AWS instances OS
  become: True
  remote_user: ubuntu
  gather_facts: False
  vars:
    trainingpassword: training
    ansible_ssh_private_key_file: /Users/alibi/aws-ansible/Training.pem
  pre_tasks:
    - name: Change instance hostname
      lineinfile:
        path: /etc/hostname
        regexp: '^ip'
        line: "{{inventory_hostname}}"
        owner: root
        group: root
        mode: '0644'

    - name: Change hosts hostname entry
      lineinfile:
        path: /etc/hosts
        insertafter: '^127\.0\.0\.1'
        line: "127.0.1.1 {{inventory_hostname}}"
        owner: root
        group: root
        mode: '0644'

    - name: Update the software cache
      apt: update_cache=yes

    - name: Install Aptitude
      apt:
        name: aptitude

    - name: Add extra repos
      shell: add-apt-repository -y ppa:atareao/atareao && apt install -y linux-headers-$(uname -r)

    - name: Install Ubuntu Repo based tools
      apt:
        name: "{{ packages }}"
        update_cache: yes
      vars:
        packages:
        - autoconf
        - libtool
        - openjdk-8-jre
        - default-jre
        - openjdk-8-jre-headless
        - libcanberra-gtk3-module
        - libcanberra-gtk-module
        - libxml2-dev
        - libxml2
        - liblzma-dev
        - curl
        - libcurl4-openssl-dev
        - build-essential
        - make
        - gcc
        - automake
        - libssl-dev
        - zlib1g-dev
        - libbz2-dev
        - python3
        - python
        - python3-pip
        - python-pip
        - gnome-session
        - ubuntu-desktop
        - lightdm
        - mesa-utils
        - power-commands
        - chromium-browser
        - ubuntu-restricted-extras
        - unrar
        - rar
        - icedax
        - lame
        - sharutils
        - unace
        - zip
        - unzip
        - p7zip-full
        - p7zip-rar
        - flashplugin-installer
        - bleachbit
        - openssh-server
        - htop
        - nload
        - git
        - python-dbus
        - python-gobject
        - libmpeg3-dev
        - cmake
        - libjpeg8
        - libglib2.0-dev
        - libglib2.0-0
        - libexpat1
        - libxss1
        - libudev1
        - libudev-dev
        - libflac++-dev
        - libflac-dev
        - libswscale-dev
        - expect
        - nfs-common
        - libglvnd-dev
        - libglvnd-core-dev
        - libglvnd0
        - pkg-config
        - x11-xserver-utils
        - gcc
        - make
        - linux-aws
        - awscli
        - ubuntu-desktop
        - xterm
        - xorg
        - grace
        - libncurses5-dev
        - libncursesw5-dev
        - libxbae4m
        - subversion
        - python3-dev
        - sudo

#    - name: Remove gdm3 and what follows
#      apt:
#        name: "{{ packages }}"
#        state: absent
#      vars:
#        packages:
#        - gdm3
#        - gnome-initial-setup
#      ignore_errors: yes

    - name: Install languepacks
      shell: |
        apt -y install `check-language-support -l fr`
        apt -y install `check-language-support -l en`
        apt -y install `check-language-support -l es`
        apt -y install `check-language-support -l de`
        apt -y install `check-language-support -l it`

    - name: Set lightdm as default display manager
      script: /Users/alibi/aws-ansible/dpkgreconfig

    - name: Upgrade all software
      apt: upgrade=yes

    - name: Remove useless packages from the cache
      apt:
        autoclean: yes

    - name: Remove dependencies that are no longer required
      apt:
        autoremove: yes

    - name: Reboot the VMs to enable LINUX-AWS package
      reboot:
        msg: System reboot inititated by Ansible
        reboot_timeout: 120

    - name: Configrue nvidia driver black list on modprob
      blockinfile:
        path: /etc/modprobe.d/blacklist.conf
        block: |
          blacklist vga16fb
          blacklist nouveau
          blacklist rivafb
          blacklist nvidiafb
          blacklist rivatv

    - name: Add nouveau blacklist to grub
      lineinfile: dest=/etc/default/grub regexp='^GRUB_CMDLINE_LINUX=""' line='GRUB_CMDLINE_LINUX="rdblacklist=nouveau"'

    - name: Update Grub settings to apply new blacklist changes
      shell: sudo update-grub

    - name: Download the Nvidia G4 Driver from AWS S3
      shell: aws s3 cp --recursive s3://ec2-linux-nvidia-drivers/g4/latest/ /usr/local/

    - name: Set Nvidia driver execute permissions
      shell: chmod +x /usr/local/NVIDIA-Linux-x86_64*.run

    - name: Stop X server to install nvidia driver
      shell: |
        systemctl stop lightdm
        systemctl stop gdm3

    - name: Install NVIDIA GRID driver
      shell: sudo /bin/sh /usr/local/NVIDIA-Linux-x86_64*.run -q -a -n -X -s
      async: 60
      poll: 5

    - name: Start X server to install nvidia driver
      shell: |
        systemctl start lightdm

    - name: Remove NVIDIA driver installer file
      shell: rm /usr/local/NVIDIA-Linux-x86_64*.run
      ignore_errors: yes

    - name: Reboot the VMs to enable Nvidia GRID Driver
      reboot:
        msg: System reboot inititated by Ansible
        reboot_timeout: 120

    #- name: Add nvidia grid conf
    #  lineinfile: dest=/etc/nvidia/gridd.conf regexp='^EnableUI=FALSE' line='EnableUI=TRUE'

    - name: Configure Apport to stop messing around
      lineinfile:
        dest: /etc/default/apport
        regexp: '^enabled=1'
        line: enabled=0

    - name: Stop new LTS release promotion box
      shell: sudo sed -i 's/Prompt=.*/Prompt=never/' /etc/update-manager/release-upgrades


    - name: Stop gdm initial setup
      lineinfile:
        dest: /etc/gdm3/custom.conf
        regexp: '^# Enabling timed login'
        line: 'InitialSetupEnable=false'

    - name: Stop gdm initial setup 2.0
      lineinfile:
        dest: /etc/xdg/autostart/gnome-initial-setup-first-login.desktop
        regexp: '^Exec=/usr/lib/gnome-initial-setup/gnome-initial-setup --existing-user'
        line: '##Exec=/usr/lib/gnome-initial-setup/gnome-initial-setup --existing-user'

    - name: Add the user training
      user:
        name: training
        comment: Training
        password: "{{ trainingpassword | password_hash('sha512') }}"
        shell: /bin/bash
        groups: sudo,audio,video
        append: yes
        home: /home/training
      ignore_errors: true

    - name: Create training user Desktop folder
      file:
        path: /home/training/Desktop/
        state: directory
        mode: 0755
        owner: training
        group: training

    - name: Create PenleopeCloud folder
      file:
        path: "{{ efs_mount_dir }}"
        state: directory
        mode: 0777
        owner: training
        group: training

    - name: Ensure EFS volume is mounted.
      mount:
        path: "{{ efs_mount_dir }}"
        src: "{{ efs_file_system_dns }}:/"
        fstype: nfs
        opts: defaults
        #vers=4
        state: mounted

    - name: Change training user login method
      shell: gpasswd -a training nopasswdlogin
      ignore_errors: true

    - name: Update lightdm config
      blockinfile:
        path: /etc/lightdm/lightdm.conf
        create: yes
        block: |
          [SeatDefaults]
          autologin-user=training
          autologin-guest=false
          [Seat:seat*]
          greeter-setup-script=xhost +LOCAL:

    - name: Update lightdm config
      blockinfile:
        path: /var/lib/AccountsService/users/ubuntu
        create: yes
        block: |
          [User]
          SystemAccount=true

    - name: Set graphical target
      shell: systemctl get-default && systemctl set-default graphical.target && systemctl isolate graphical.target

    - name: Run an Nvidia xconfig
      shell: nvidia-xconfig

    - name: Add an apt key for Nice DCV repo
      shell: wget https://d1uj6qtbmh3dt5.cloudfront.net/NICE-GPG-KEY -P /usr/local/ && gpg --import /usr/local/NICE-GPG-KEY

    - name: Get and extract Nice DCV server archive
      unarchive:
        src: "https://d1uj6qtbmh3dt5.cloudfront.net/2020.2/Servers/nice-dcv-2020.2-9508-ubuntu1804-x86_64.tgz"
        dest: /usr/local/
        remote_src: yes
        mode: '0777'

    - name: Install the Nice DCV server deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-server_2020.2.9508-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV xdcv deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-xdcv_2020.2.359-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV GPU sharing dcv-gl deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-gl_2020.2.881-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV dcv-gl test deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-gltest_2020.2.259-1_amd64.ubuntu1804.deb

    - name: Install the Nice DCV simple external auth deb package
      apt:
        deb: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64/nice-dcv-simple-external-authenticator_2020.2.125-1_amd64.ubuntu1804.deb

    - name: Delete DCV server deb packages installer
      file:
        path: /usr/local/nice-dcv-2020.2-9508-ubuntu1804-x86_64
        state: absent

    - name: Install DKMS USB driver
      apt:
        name: dkms

    - name: Install the DCV USB drivers
      shell: dcvusbdriverinstaller --quiet

    - name: Fix console sessions
      shell: systemctl isolate multi-user.target && dcvgladmin disable && dcvgladmin enable && systemctl isolate graphical.target

    - name: Reconfigure dcvserver config file session creation
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#create-session = true' line='create-session = true'

    - name: Reconfigure dcvserver config file virtual-session
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#enable-gl-in-virtual-sessions = "default-on"' line='enable-gl-in-virtual-sessions = "default-on"'

    - name: Reconfigure dcvserver config file owner
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#owner = ""' line='owner="training"'

    - name: Reconfigure dcvserver config file owner
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#authentication="none"' line='authentication="system"'

    - name: Reconfigure dcvserver config file timeout
      lineinfile: dest=/etc/dcv/dcv.conf regexp='^#idle-timeout=120' line='idle-timeout=600'

    - name: Reconfigure dcvserver config file
      blockinfile:
        path: /etc/dcv/dcv.conf
        block: |
          cuda-devices=['0']
          [display/linux]
          gl-displays=[':0.0',':0.1']
          [clipboard]
          primary-selection-paste=true

    - name: Service dcvserver enable and start
      shell: systemctl enable dcvserver && systemctl restart dcvserver

    - name: Reboot the course instances to apply update and enable drivers
      reboot:
        msg: System reboot inititated by Ansible to start user session
        reboot_timeout: 120

################################################################################################
################################################################################################

  tasks:
  - name: Create PeneloepCloud Tools folder
    file:
      path: /media/penelopecloud/tools/
      state: directory
      mode: 0777
      owner: training
      group: training
    poll: 1

# Pymol edu ################################################
  - name: Download Pymol
    get_url:
      url: "https://pymol.org/installers/PyMOL-2.4.1_198-Linux-x86_64-py37.tar.bz2"
      dest: /media/penelopecloud/tools/PyMOL-2.4.1_198-Linux-x86_64-py37.tar.bz2
      mode: '0777'
    run_once: true

  - name: Extract Pymol archive
    unarchive:
      src: /media/penelopecloud/tools/PyMOL-2.4.1_198-Linux-x86_64-py37.tar.bz2
      dest: /usr/local/
      remote_src: yes
      mode: '0777'

  - name: Copy Pymol licence file
    copy:
      src: /Users/alibi/Documents/Courses_Playbooks/pymol-edu-license-jun2020.lic
      dest: /usr/local/pymol/share/pymol/license.lic
      mode: 0777

  - name: Create Pymol Symlink
    file:
      src: /usr/local/pymol/pymol
      dest: /usr/local/bin/pymol
      state: link
    ignore_errors: yes

  - name: Create Pymol Desktop file
    file:
      path: /home/training/Desktop/pymol.desktop
      state: touch
      owner: training
      group: training
      mode: '0777'

  - name: Fill in Pymol Desktop file
    blockinfile:
      path: /home/training/Desktop/pymol.desktop
      block: |
        [Desktop Entry]
        Type=Application
        Terminal=false
        Name=Pymol 2.4.1
        Icon=/usr/local/pymol/share/pymol/data/pymol/icons/icon2_128x128.png
        Exec=/usr/local/pymol/pymol

# Jupyter ################################################
  - name: Install Jupyter
    shell: pip3 install -U jupyter pandas matplotlib requests solrq numpy scipy

# Anaconda ################################################
  - name: Download Anaconda3
    get_url:
      url: "https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh"
      dest: /media/penelopecloud/tools/Anaconda3.sh
      mode: '0777'
    run_once: true

  - name: Copy Anaconda to other VMs
    copy:
      src: /media/penelopecloud/tools/Anaconda3.sh
      dest: /usr/local/Anaconda3.sh
      remote_src: yes
      mode: '0777'

  - name: Install anaconda3 requirements
    apt:
      name:
        - python3-pip
        - python3-dev
        - libgl1-mesa-glx
        - libegl1-mesa
        - libxrandr2
        - libxrandr2
        - libxss1
        - libxcursor1
        - libxcomposite1
        - libasound2
        - libxi6
        - libxtst6
      update_cache: yes

  - name: Install Pip requirements
    shell: pip3 install -U Requests pycosat PyYaml Snakemake

  - name: Install Anaconda3
    shell: /usr/local/Anaconda3.sh -b
    become: yes
    become_user: training
    args:
      chdir: /home/training/
    ignore_errors: yes

  - name: Create Conda Symlink
    file:
      src: /home/training/anaconda3/bin/conda
      dest: /usr/local/bin/conda
      state: link
    ignore_errors: yes

  - name: Update Anaconda3
    shell: |
      source /home/training/anaconda3/bin/activate
      conda init
      conda update conda
      conda config --set auto_activate_base true

    become: yes
    become_user: training
    args:
      chdir: /home/training/
    ignore_errors: yes

  - name: Delete Conda installer
    file:
      path: /usr/local/Anaconda3.sh
      state: absent
    ignore_errors: yes

# rdkit ################################################
  - name: Install rdkit
    shell: |
      source /home/training/anaconda3/bin/activate
      conda init
      conda create -y --name myenv
      conda activate myenv
      conda install -y -c conda-forge rdkit
    become: yes
    become_user: training
    args:
      chdir: /home/training/
    async: 120
    poll: 0

# VMD ################################################
  - name: Copy VMD archive
    copy:
      src: /Users/alibi/Documents/Courses_Playbooks/vmd-1.9.3.bin.LINUXAMD64-CUDA8-OptiX4-OSPRay111p1.opengl.tar.gz
      dest: /media/penelopecloud/tools/vmd.tar.gz
      mode: '0777'
    run_once: true

  - name: Extract VMD archive
    unarchive:
      src: /media/penelopecloud/tools/vmd.tar.gz
      dest: /usr/local/
      remote_src: yes
      mode: '0777'

  - name: Compile VMD
    shell: |
      ./configure LINUXAMD64
      cd ./src
      make
      make install
    args:
      chdir: /usr/local/vmd-1.9.3

  - name: Fix VMD SSE4.1. requirements
    shell: |
      echo "export VMDNOOSPRAY=1" >> /home/training/.profile
      echo "export VMDNOOSPRAY=1" >> /home/training/.bashrc
      ##echo "export VMDNOOSPRAY=1" >> /etc/bash.bashrc

  - name: Delete VMD archive
    file:
      path: /usr/local/vmd.tar.gz
      state: absent
    ignore_errors: yes

# Gromacs 2019 and Plumed ################################################
  - name: install Gromacs 2019 deps
    shell: apt install -y doxygen libnl-utils graphviz fftw-dev fftw-docs fftw2 libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-doc libfftw3-long3 libfftw3-quad3 sfftw-dev sfftw2 libopenmpi-dev

  - name: Download Gromacs 2019
    get_url:
      url: "ftp://ftp.gromacs.org/pub/gromacs/gromacs-2019.tar.gz"
      dest: /media/penelopecloud/tools/gromacs-2019.tar.gz
      mode: '0777'
    run_once: true

  - name: Extract Gromacs 2019 archive
    unarchive:
      src: /media/penelopecloud/tools/gromacs-2019.tar.gz
      dest: /home/training/
      remote_src: yes
      mode: '0777'
      owner: training

  - name: Download Plumed 2.6.2
    get_url:
      url: "https://github.com/plumed/plumed2/releases/download/v2.6.2/plumed-2.6.2.tgz"
      dest: /media/penelopecloud/tools/plumed-2.6.2.tgz
      mode: '0777'
    run_once: true

  - name: Extract Plumed 2.6.2 archive
    unarchive:
      src: /media/penelopecloud/tools/plumed-2.6.2.tgz
      dest: /usr/local/
      remote_src: yes
      mode: '0777'

  - name: Compile Plumed with MPI
    shell: |
      export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
      ##echo "export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH" >> /etc/bash.bashrc
      #echo "export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH" >> /home/training/.bashrc
      ./configure --prefix=/usr/local/ CXX=mpic++ --enable-mpi
      make -j 6
      make check -j 6
      make doc -j 6
      make test -j 6
      umask 022
      make install
      sudo ldconfig
    args:
      chdir: /usr/local/plumed-2.6.2/

  - name: Patch Gromacs 2019 with Plumed
    shell: |
      export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
      plumed patch -p -e gromacs-2019.6
    args:
      chdir: /home/training/gromacs-2019/

  - name: Compile Gromacs 2019
    shell: |
      mkdir build
      cd ./build
      cmake .. -DGMX_BUILD_OWN_FFTW=ON -DREGRESSIONTEST_DOWNLOAD=ON -DGMX_MPI=on -DCMAKE_INSTALL_PREFIX=/home/training/gromacs-2019
      make -j 6
      make check -j 6
      sudo make install
    args:
      chdir: /home/training/gromacs-2019

# Gromacs 2020.4  ################################################
  - name: install Gromacs deps
    shell: apt install -y doxygen libnl-utils graphviz fftw-dev fftw-docs fftw2 libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-doc libfftw3-long3 libfftw3-quad3 sfftw-dev sfftw2 libopenmpi-dev

  - name: Download Gromacs 2020
    get_url:
      url: "ftp://ftp.gromacs.org/pub/gromacs/gromacs-2020.4.tar.gz"
      dest: /media/penelopecloud/tools/gromacs-2020.4.tar.gz
      mode: '0777'
    run_once: true

  - name: Extract Gromacs 2020.4 archive
    unarchive:
      src: /media/penelopecloud/tools/gromacs-2020.4.tar.gz
      dest: /home/training/
      remote_src: yes
      mode: '0777'
      owner: training

  - name: Compile Gromacs 2020.4
    shell: |
      mkdir build
      cd ./build
      cmake .. -DGMX_BUILD_OWN_FFTW=ON -DREGRESSIONTEST_DOWNLOAD=ON -DGMX_MPI=on -DCMAKE_INSTALL_PREFIX=/home/training/gromacs-2020.4
      make -j 6
      make check -j 6
      sudo make install
    args:
      chdir: /home/training/gromacs-2020.4

# PMX ################################################
  - name: Download pmx opensource
    git:
      repo: https://github.com/deGrootLab/pmx.git
      dest: /usr/local/pmx
      version: develop
    ignore_errors: yes

  - name: Change pmx folder permissions
    file:
      path: /usr/local/pmx
      mode: '0777'
      recurse: yes

  - name: Install pmx python3 packages
    shell: pip3 install -U matplotlib numpy scipy

  - name: Install pmx
    shell: |
      python3 setup.py install
      pip3 install .
    args:
      chdir:  /usr/local/pmx


##########################################################################
##########################################################################
# Final configuration ################################################
  - name: Copy Chromium Desktop file
    copy:
      src: /usr/share/applications/chromium-browser.desktop
      dest: /home/training/Desktop/chromium-browser.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Firefox Desktop file
    copy:
      src: /usr/share/applications/firefox.desktop
      dest: /home/training/Desktop/firefox.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Terminal Desktop file
    copy:
      src: /usr/share/applications/gnome-terminal.desktop
      dest: /home/training/Desktop/gnome-terminal.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Word Desktop file
    copy:
      src: /usr/share/applications/libreoffice-writer.desktop
      dest: /home/training/Desktop/libreoffice-writer.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Copy Excel Desktop file
    copy:
      src: /usr/share/applications/libreoffice-calc.desktop
      dest: /home/training/Desktop/libreoffice-calc.desktop
      remote_src: yes
      owner: training
      group: training
      mode: '0777'

  - name: Create user autostater folder
    file:
      path: /home/training/.config/autostart
      state: directory

  - name: Create Desktop truster desktop file
    file:
      path: /home/training/.config/autostart/desktop-truster.desktop
      state: touch
      owner: training
      group: training
      mode: '0777'


  - name: Create Desktop truster Bash script file
    file:
      path: /home/training/.config/autostart/desktop-truster.sh
      state: touch
      owner: training
      group: training
      mode: '0777'


  - name: Fill-in Desktop truster desktop file
    blockinfile:
      path: /home/training/.config/autostart/desktop-truster.desktop
      block: |
        [Desktop Entry]
        Type=Application
        Comment=Autostarter to trust all desktop files
        Terminal=false
        Name=Desktop Truster
        Exec=/home/training/.config/autostart/desktop-truster.sh

  - name: Fill-in Desktop truster Bash script file
    blockinfile:
      path: /home/training/.config/autostart/desktop-truster.sh
      block: |
        #!/bin/bash
        # Wait for nautilus-desktop
        while ! pgrep -f 'nautilus-desktop' > /dev/null; do
          sleep 1
        done
        # enable user home default desktop icons
        gsettings set org.gnome.nautilus.desktop home-icon-visible  'true'
        gsettings set org.gnome.nautilus.desktop volumes-visible 'true'
        gsettings set org.gnome.nautilus.desktop trash-icon-visible 'true'
        gsettings set org.gnome.desktop.lockdown disable-lock-screen 'true'
        gsettings set org.gnome.desktop.screensaver lock-enabled 'false'
        # Trust all desktop files
        for i in /home/training/Desktop/*.desktop; do
          [ -f "${i}" ] || break
          gio set "${i}" "metadata::trusted" yes
          # gio set "${i}" "metadata::trusted" true (ubuntu 19.04 onward)
        done
        # Restart nautilus, so that the changes take effect (otherwise we would have to press F5)
        killall nautilus-desktop && nautilus-desktop &
        # Remove X from this script, so that it won't be executed next time
        chmod -x ${0}

  - name: Reboot the course instances to apply fixes and tweaks
    reboot:
      msg: System reboot inititated by Ansible to start user session
      reboot_timeout: 120

##########################################################################
##########################################################################
#- hosts: ThinClientTR2
#ThinClientTR1 ThinClientTR2
#  name: Manage dcv connection on thin clients
#  gather_facts: false
#  tasks:
#    - name: Ensure nice-dcv-client installed
#      win_shell: choco install nice-dcv-client

#    - name: Copy DCV conection files to thinclients
#      win_copy:
#        src: "/Users/alibi/aws-ansible/dcv-files/{{ inventory_hostname }}.dcv"
#        dest: 'C:\Users\Public\Desktop\AWSConnection.dcv'
#      ignore_errors: yes
